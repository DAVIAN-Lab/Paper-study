# DAVIAN Lab. Seminar (2024)

### Review
- 1 hour in-depth review per paper
  
|     Date    | Topic | Presenter | Video |
|:-----------:|:----------------------------------------|:------:|:------:
| 01.25 2024  | Diffusion Model Alignment Using Direct Preference Optimization | 형준하 | [Video](https://www.youtube.com/watch?v=ERIoc2vtam4&t=4100s)
| 01.18 2024  | ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings | 백유진  | [Video](https://www.youtube.com/watch?v=ERIoc2vtam4&t=1s)
| 01.11 <br>2024  | DayDreamer: World Models for Physical Robot Learning | 이병근  | [Video](https://youtu.be/Fn2PJzW11mg?t=3800)
| 01.04 2024  | Computer Vision in The Wild | 송준하 | [Video](https://youtu.be/4V5R_s8i_us?t=5)
| 12.21 2023  | Language Models Don’t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting | 최민석 | [Slide]() | [Video](https://youtu.be/UnSlEeMmx2s?t=5)
| 12.07 2023  | DALL-E 3: Improving Image Generation with Better Captions | 황성원 | [Video](https://youtu.be/C_areldwHYs?t=3610)
| ~ 2023 | [Link](https://github.com/DAVIAN-Lab/Paper-study/blob/master/paper-list(2023).md) |  |  |  |


### Sprint
- 5 minutes quick review per paper

|     Date    | Topic | Presenter | Video |
|:-----------:|:----------------------------------------|:------:|:------:
| 01.25 2024  | Bad Students Make Great Teachers <br> Rethinking FID: Towards a Better Evaluation Metric for Image Generation <br> InstantID: Zero-shot Identity-Preserving Generation in Seconds <br> AI 커버곡 어떻게 만들까? | 박민호 <br> 조영우 | [Video](https://www.youtube.com/watch?v=ERIoc2vtam4&t=4100s)
| 01.18 2024  |  Tokenizer is Key to Visual Generation <br>  Divide and not forget: Ensemble of selectively trained experts in Continual Learning <br> FITS: Modeling Time Series with 10k Parameters <br> ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs <br> Pixart-alpha and Pixart-delta <br> Generative Models: What do they know? Do they know things? <br> Instruct-Imagen: Image Generation with Multi-modal Instruction <br> MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation <br> Boundary Attention: Learning to Find Faint Boundaries at Any Resolution <br> TrustLLM: Trustworthiness in Large Language Models <br> Tuning Language Models by Proxy <br> Improving Text Embeddings with Large Language Models | 조호준 <br> 윤주열 <br> 박준우 <br> 최승환  | [Video](https://www.youtube.com/watch?v=ERIoc2vtam4&t=1s)
| 01.11 <br>2024  | Are Emergent Abilities of Large Language Models a Mirage? <br> Scaling Data-Constrained Language Models <br> Direct Preference Optimization: Your Language Model is Secretly a Reward Model <br> Mixtral of Experts <br> SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling <br> LLaMA Pro: Progressive LLaMA with Block Expansion <br> Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets <br> FreeU: Free Lunch in Diffusion U-Net <br> Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation <br> TIBET: Identifying and Evaluating Biases in Text-to-Image Generative Models <br> ITI-GEN: Inclusive Text-to-Image Generation <br> Fair Text-to-Image Diffusion via Fair Mapping | 양소영 <br> 정하원 <br> 정채연 <br> 김정호  | [Video](https://youtu.be/Fn2PJzW11mg?t=3800)
| 01.04 2024  | Siamese Masked Autoencoders <br> Learning to Reason and Memorize with Self-Notes <br> Video Prediction Models as Rewards for Reinforcement Learning <br> Pixel Aligned Language Models <br> Gradient-based Parameter Selection for Efficient Fine-Tuning <br> SegGPT: Segmenting Everything In Context <br> Gemini vs GPT-4V: A Preliminary Comparison and Combination <br> Large Language Model Bias Index <br> GPTBIAS: A Comprehensive Framework for Evaluating Bias in Large Language Models <br> I2V-Adapter: A General Image-to-Video Adapter for Video Diffusion Model <br> DreamTuner: Single Image is Enough for Subject-Driven Generation <br> StreamDiffusion: A Pipeline-level Solution for Real-time Interactive Generation | 이승일 <br> 이상현 <br> 황동윤 <br> 정소현 | [Video](https://youtu.be/4V5R_s8i_us?t=5)
| 12.21 2023  | ERM++: An Improved Baseline for Domain Generalization <br> DATACOMP: In search of the next generation of multimodal datasets <br> AI2. Does progress on imagenet transfer to real-world datasets? <br> Aligning Large Language Models through Synthetic Feedback <br> Self-Evaluation Improves Selective Generation in Large Language Models <br> Large Language Models as Optimizers <br> EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything <br> SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing <br> Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision| 이도현 <br> 조영우 <br> 임혜수 <br> 최새미 | [Video](https://youtu.be/UnSlEeMmx2s?t=5)
| 12.14 2023  | Analyzing and Improving the Training Dynamics of Diffusion Models <br> VideoSwap: Customized Video Subject Swapping with Interactive Semantic Point Correspondence <br> Cache Me if You Can: Accelerating Diffusion Models through Block Caching <br> DreaMoving: A Human Video Generation Framework based on Diffusion Models <br> Vision Transformers Need Registers <br> DeepCache: Accelerating Diffusion Models for Free <br> Kandinsky 3.0 Technical Report <br> FreeInit: Bridging Initialization Gap in Video Diffusion Models <br> Alpha-CLIP: A CLIP Model Focusing on Wherever You Want <br> The mechanistic basis of data dependence and abrupt learning in an in-context classification task <br>  Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction <br> LRM: Large Reconstruction Model for Single Image to 3D | 최승환 <br> 박민호 <br> 박준우 <br> 김태성 | [Video](https://youtu.be/OqI59NRx-nI?t=60)
| 12.07 2023  | Towards Accurate Differential Diagnosis with Large Language Models <br> Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models <br> Communicative Agents for Software Development <br> IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models <br> LCM-LoRA: A Universal Stable-Diffusion Acceleration Module <br> Adversarial Diffusion Distillation <br> Training Chain-of-Thought via Latent-Variable Inference <br> The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning <br> GAIA: A Benchmark for General AI Assistants <br> FaceStudio: Put Your Face Everywhere in Seconds <br> ImageDream: Image-Prompt Multi-view Diffusion for 3D Generation <br> Describing Differences in Image Sets with Natural Language | 조호준 <br> 윤주열 <br> 김진희 | [Video](https://youtu.be/C_areldwHYs?t=3610)
| ~ 2023 | [Link](https://github.com/DAVIAN-Lab/Paper-study/blob/master/paper-list(2023).md) |  |  |  |
